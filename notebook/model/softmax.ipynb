{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fb3913",
   "metadata": {},
   "source": [
    "# HỒI QUY SOFTMAX (MULTINOMIAL LOGISTIC REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e570b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183ec37",
   "metadata": {},
   "source": [
    "## Hàm softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "966cffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(y, C):\n",
    "    Y = sparse.coo_matrix((np.ones_like(y), (y, np.arange(len(y)))), shape=(C, len(y))).toarray()\n",
    "    return Y\n",
    "\n",
    "def softmax_stable(Z):\n",
    "    e_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    return e_Z / e_Z.sum(axis=0)\n",
    "\n",
    "def softmax(Z):\n",
    "    e_Z = np.exp(Z)\n",
    "    return e_Z / e_Z.sum(axis=0)\n",
    "\n",
    "def softmax_regression(X, y, W_init, eta=0.05, tol=1e-4, max_count=10000):\n",
    "    W = [W_init]\n",
    "    C = W_init.shape[1]\n",
    "    Y = convert_labels(y, C)\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "\n",
    "    count = 0\n",
    "    check_w_after = 1500\n",
    "    while count < max_count:\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = Y[:, i].reshape(C, 1)\n",
    "            ai = softmax(np.dot(W[-1].T, xi))\n",
    "            W_new = W[-1] + eta * xi.dot((yi - ai).T)\n",
    "            count += 1\n",
    "            if count % check_w_after == 0:\n",
    "                if np.linalg.norm(W_new - W[-check_w_after]) < tol:\n",
    "                    return W\n",
    "            W.append(W_new)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33c63ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dự đoán và đánh giá các chỉ số \n",
    "def pred(W, X):\n",
    "    A = softmax_stable(W.T.dot(X))\n",
    "    return np.argmax(A, axis=0)\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    auc = roc_auc_score(pd.get_dummies(y_true), pd.get_dummies(y_pred), average='macro', multi_class='ovr')\n",
    "    print(f\"AUC (macro average): {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654d3e3",
   "metadata": {},
   "source": [
    "## DỮ LIỆU GỐC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06f8be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dữ liệu\n",
    "df = pd.read_csv(\"../../data/data_processed/data_processed.csv\")\n",
    "\n",
    "# Tách đặc trưng và nhãn\n",
    "X = df.drop(columns=[\"NSP\"]).values\n",
    "y = df[\"NSP\"].values - 1  # Chuyển về 0,1,2\n",
    "\n",
    "# Chuẩn hóa\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Thêm bias\n",
    "X_scaled = np.hstack([np.ones((X_scaled.shape[0], 1)), X_scaled])\n",
    "C = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd137770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.94      0.93       332\n",
      "         1.0       0.58      0.59      0.59        59\n",
      "         2.0       0.82      0.66      0.73        35\n",
      "\n",
      "    accuracy                           0.87       426\n",
      "   macro avg       0.78      0.73      0.75       426\n",
      "weighted avg       0.87      0.87      0.87       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[312  17   3]\n",
      " [ 22  35   2]\n",
      " [  4   8  23]]\n",
      "AUC (macro average): 0.8054\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93       497\n",
      "         1.0       0.50      0.72      0.59        88\n",
      "         2.0       0.83      0.55      0.66        53\n",
      "\n",
      "    accuracy                           0.86       638\n",
      "   macro avg       0.76      0.73      0.73       638\n",
      "weighted avg       0.88      0.86      0.86       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[454  40   3]\n",
      " [ 22  63   3]\n",
      " [  2  22  29]]\n",
      "AUC (macro average): 0.8139\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       663\n",
      "         1.0       0.62      0.65      0.63       118\n",
      "         2.0       0.79      0.70      0.74        70\n",
      "\n",
      "    accuracy                           0.88       851\n",
      "   macro avg       0.78      0.77      0.77       851\n",
      "weighted avg       0.88      0.88      0.88       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[626  35   2]\n",
      " [ 30  77  11]\n",
      " [  8  13  49]]\n",
      "AUC (macro average): 0.8354\n"
     ]
    }
   ],
   "source": [
    "# Hàm huấn luyện và đánh giá với tỉ lệ cho trước\n",
    "def train_and_evaluate(X, y, test_size):\n",
    "    print(f\"\\n--- Tỉ lệ train:test = {int((1-test_size)*10)}:{int(test_size*10)} ---\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "    X_train_T = X_train.T\n",
    "    X_test_T = X_test.T\n",
    "    d = X_train_T.shape[0]\n",
    "\n",
    "    W_init = np.random.randn(d, C)\n",
    "    W = softmax_regression(X_train_T, y_train, W_init)[-1]\n",
    "\n",
    "    y_pred = pred(W, X_test_T)\n",
    "    evaluate_model(y_test, y_pred)\n",
    "\n",
    "# Chạy với các tỉ lệ\n",
    "for test_size in [0.2, 0.3, 0.4]:\n",
    "    train_and_evaluate(X_scaled, y, test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b2309",
   "metadata": {},
   "source": [
    "### Đánh giá tổng quan theo độ chính xác và AUC\n",
    "\n",
    "| Tỉ lệ train:test | Accuracy | AUC (macro) | Macro F1-score |\n",
    "|------------------|----------|-------------|----------------|\n",
    "| 8:2              | 0.8779   | 0.9568      | 0.7665         |\n",
    "| 7:3              | 0.8840   | 0.9545      | 0.7609         |\n",
    "| 6:4              | **0.8931** | **0.9631**    | **0.7898**       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b45b6",
   "metadata": {},
   "source": [
    "**Lớp 0 (bình thường):**\n",
    "Precision và Recall đều rất cao ở cả 3 tỉ lệ (trên 92%).\n",
    "\n",
    "Đây là lớp chiếm đa số nên mô hình học tốt nhất.\n",
    "\n",
    "**Lớp 1 (nghi ngờ):**\n",
    "Hiệu suất biến động rõ rệt, Precision/Recall dao động trong khoảng 59–68%.\n",
    "\n",
    "Tỉ lệ 6:4 cho kết quả ổn định hơn về F1 (0.63), dù Recall hơi giảm nhẹ.\n",
    "\n",
    "**Lớp 2 (bất thường):**\n",
    "Nhạy cảm với sự thay đổi tỉ lệ chia.\n",
    "\n",
    "Tỉ lệ 6:4 có Precision 85% và F1-score gần 0.79 — tốt nhất trong 3 lựa chọn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4588a",
   "metadata": {},
   "source": [
    "Lớp 1 (suspect) thường có precision và recall thấp do đặc điểm đặc trưng của nó nằm giữa hai lớp còn lại (normal và pathologic), khiến mô hình dễ nhầm lẫn. Đây là lớp trung gian về mặt y học, nên các đặc trưng không phân tách rõ ràng, dẫn đến việc mô hình thường dự đoán sai sang lớp 0 hoặc lớp 2. Đồng thời, softmax regression là mô hình tuyến tính nên càng gặp khó khăn khi ranh giới giữa các lớp không rõ ràng hoặc có sự chồng lấn trong không gian đặc trưng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c099a",
   "metadata": {},
   "source": [
    "## DỮ LIỆU GIẢM CHIỀU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489ce84",
   "metadata": {},
   "source": [
    "### GIẢM TRƯỚC CHIA SAU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c934533",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "309331cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Đánh giá với PCA ---\n",
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.78      0.87       332\n",
      "         1.0       0.44      0.88      0.58        59\n",
      "         2.0       0.43      0.51      0.47        35\n",
      "\n",
      "    accuracy                           0.77       426\n",
      "   macro avg       0.62      0.73      0.64       426\n",
      "weighted avg       0.86      0.77      0.80       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[260  51  21]\n",
      " [  4  52   3]\n",
      " [  1  16  18]]\n",
      "AUC (macro average): 0.8136\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.79      0.87       497\n",
      "         1.0       0.45      0.78      0.57        88\n",
      "         2.0       0.39      0.57      0.47        53\n",
      "\n",
      "    accuracy                           0.77       638\n",
      "   macro avg       0.60      0.71      0.64       638\n",
      "weighted avg       0.85      0.77      0.80       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[395  61  41]\n",
      " [ 14  69   5]\n",
      " [  0  23  30]]\n",
      "AUC (macro average): 0.8024\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.80      0.88       663\n",
      "         1.0       0.51      0.74      0.60       118\n",
      "         2.0       0.40      0.79      0.53        70\n",
      "\n",
      "    accuracy                           0.79       851\n",
      "   macro avg       0.63      0.77      0.67       851\n",
      "weighted avg       0.86      0.79      0.81       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[529  69  65]\n",
      " [ 13  87  18]\n",
      " [  0  15  55]]\n",
      "AUC (macro average): 0.8385\n"
     ]
    }
   ],
   "source": [
    "pca_df = pd.read_csv(\"../../data/dimension_reduction/pca/pca_all.csv\")\n",
    "pca_X = pca_df.drop(columns=[\"NSP\"]).values\n",
    "pca_y = pca_df[\"NSP\"].values - 1\n",
    "scaler = StandardScaler()\n",
    "pca_X_scaled = scaler.fit_transform(pca_X)\n",
    "\n",
    "print(\"--- Đánh giá với PCA ---\")\n",
    "for test_size in [0.2, 0.3, 0.4]:\n",
    "    train_and_evaluate(pca_X_scaled, pca_y, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ddb2d0",
   "metadata": {},
   "source": [
    "### Kết quả đánh giá với PCA\n",
    "\n",
    "| Tỉ lệ chia | Accuracy | AUC (macro) | F1-score (macro) |\n",
    "|------------|----------|-------------|------------------|\n",
    "| 8:2        | 0.7606   | 0.8786      | 0.6042           |\n",
    "| 7:3        | **0.7759**   | 0.8740      | 0.6356           |\n",
    "| 6:4        | 0.7591   | **0.9192**  | **0.6380**       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8974105",
   "metadata": {},
   "source": [
    "### LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0d0da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Đánh giá với LDA ---\n",
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.77      0.86       332\n",
      "         1.0       0.47      0.80      0.59        59\n",
      "         2.0       0.37      0.66      0.47        35\n",
      "\n",
      "    accuracy                           0.77       426\n",
      "   macro avg       0.60      0.74      0.64       426\n",
      "weighted avg       0.86      0.77      0.79       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257  42  33]\n",
      " [  6  47   6]\n",
      " [  0  12  23]]\n",
      "AUC (macro average): 0.8195\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.76      0.86       497\n",
      "         1.0       0.44      0.92      0.59        88\n",
      "         2.0       0.42      0.57      0.48        53\n",
      "\n",
      "    accuracy                           0.77       638\n",
      "   macro avg       0.62      0.75      0.65       638\n",
      "weighted avg       0.87      0.77      0.79       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[378  82  37]\n",
      " [  3  81   4]\n",
      " [  0  23  30]]\n",
      "AUC (macro average): 0.8275\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.78      0.87       663\n",
      "         1.0       0.46      0.88      0.60       118\n",
      "         2.0       0.43      0.59      0.49        70\n",
      "\n",
      "    accuracy                           0.78       851\n",
      "   macro avg       0.62      0.75      0.66       851\n",
      "weighted avg       0.86      0.78      0.80       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[518  94  51]\n",
      " [ 10 104   4]\n",
      " [  0  29  41]]\n",
      "AUC (macro average): 0.8262\n"
     ]
    }
   ],
   "source": [
    "lda_df = pd.read_csv(\"../../data/dimension_reduction/lda/lda_all.csv\")\n",
    "\n",
    "lda_X = lda_df.drop(columns=[\"NSP\"]).values\n",
    "lda_y = lda_df[\"NSP\"].values - 1\n",
    "lda_X_scaled = scaler.fit_transform(lda_X)\n",
    "\n",
    "print(\"\\n--- Đánh giá với LDA ---\")\n",
    "for test_size in [0.2, 0.3, 0.4]:\n",
    "  train_and_evaluate(lda_X_scaled, lda_y, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2725a18",
   "metadata": {},
   "source": [
    "### 🔹 Kết quả đánh giá với LDA\n",
    "\n",
    "| Tỉ lệ chia | Accuracy | AUC (macro) | F1-score (macro) |\n",
    "|------------|----------|-------------|------------------|\n",
    "| 8:2        | 0.7700   | 0.9112      | 0.6445           |\n",
    "| 7:3        | 0.7633   | 0.8996      | 0.6356           |\n",
    "| 6:4        | **0.7779** | **0.9294** | **0.6613**       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cd5ce",
   "metadata": {},
   "source": [
    "### So sánh giữa PCA và LDA:\n",
    "PCA: Đạt kết quả tốt nhất cho lớp 0, nhưng với các lớp 1 và 2, precision và recall thấp, có thể vì PCA chủ yếu tối ưu hóa việc giảm chiều mà không chú ý đến sự phân biệt giữa các lớp. AUC có phần thấp hơn so với LDA.\n",
    "\n",
    "LDA: Mặc dù precision của lớp 1 và 2 vẫn không quá cao, nhưng recall và AUC cho thấy LDA có khả năng phân biệt các lớp tốt hơn, đặc biệt trong các tỉ lệ chia nhỏ hơn. LDA có xu hướng cải thiện khả năng phân loại cho các lớp nhỏ hơn (lớp 1 và 2), trong khi PCA vẫn tập trung vào lớp 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b698960",
   "metadata": {},
   "source": [
    "## CHIA TRƯỚC GIẢM SAU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0598dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_from_file(train_path, test_path, test_ratio_label):\n",
    "    print(f\"\\n--- Tỉ lệ train:test = {test_ratio_label} ---\")\n",
    "    \n",
    "    # Đọc dữ liệu\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    X_train = train_df.drop(columns=['Unnamed: 0', \"NSP\"], axis=1).values.T\n",
    "    y_train = train_df['NSP'].values - 1\n",
    "    X_test = test_df.drop(columns=['Unnamed: 0', \"NSP\"], axis=1).values.T\n",
    "    y_test = test_df['NSP'].values - 1\n",
    "\n",
    "    # Huấn luyện\n",
    "    d = X_train.shape[0]\n",
    "    W_init = np.random.randn(d, C)\n",
    "    W = softmax_regression(X_train, y_train, W_init)[-1]\n",
    "\n",
    "    # Dự đoán và đánh giá\n",
    "    y_pred = pred(W, X_test)\n",
    "    evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef744904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.74      0.84       332\n",
      "         1.0       0.37      0.83      0.51        59\n",
      "         2.0       0.36      0.46      0.41        35\n",
      "\n",
      "    accuracy                           0.73       426\n",
      "   macro avg       0.57      0.68      0.59       426\n",
      "weighted avg       0.85      0.73      0.76       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245  67  20]\n",
      " [  2  49   8]\n",
      " [  3  16  16]]\n",
      "AUC (macro average): 0.7791\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.76      0.85       497\n",
      "         1.0       0.41      0.83      0.54        88\n",
      "         2.0       0.41      0.57      0.48        53\n",
      "\n",
      "    accuracy                           0.75       638\n",
      "   macro avg       0.60      0.72      0.63       638\n",
      "weighted avg       0.85      0.75      0.78       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[377  84  36]\n",
      " [  8  73   7]\n",
      " [  0  23  30]]\n",
      "AUC (macro average): 0.8049\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.81      0.88       663\n",
      "         1.0       0.29      0.31      0.30       118\n",
      "         2.0       0.31      0.71      0.43        70\n",
      "\n",
      "    accuracy                           0.74       851\n",
      "   macro avg       0.52      0.61      0.54       851\n",
      "weighted avg       0.81      0.74      0.76       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[540  72  51]\n",
      " [ 21  37  60]\n",
      " [  1  19  50]]\n",
      "AUC (macro average): 0.7432\n"
     ]
    }
   ],
   "source": [
    "pca_files = [\n",
    "    (\"../../data/dimension_reduction/pca/train_80.csv\", \"../../data/dimension_reduction/pca/test_20.csv\", \"8:2\"),\n",
    "    (\"../../data/dimension_reduction/pca/train_70.csv\", \"../../data/dimension_reduction/pca/test_30.csv\", \"7:3\"),\n",
    "    (\"../../data/dimension_reduction/pca/train_60.csv\", \"../../data/dimension_reduction/pca/test_40.csv\", \"6:4\"),\n",
    "]\n",
    "\n",
    "for train_file, test_file, label in pca_files:\n",
    "    train_test_from_file(train_file, test_file, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aaa891cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.79      0.87       332\n",
      "         1.0       0.42      0.32      0.37        59\n",
      "         2.0       0.31      0.97      0.48        35\n",
      "\n",
      "    accuracy                           0.74       426\n",
      "   macro avg       0.57      0.69      0.57       426\n",
      "weighted avg       0.83      0.74      0.76       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[262  25  45]\n",
      " [ 11  19  29]\n",
      " [  0   1  34]]\n",
      "AUC (macro average): 0.7842\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.78      0.87       497\n",
      "         1.0       0.43      0.83      0.56        88\n",
      "         2.0       0.43      0.57      0.49        53\n",
      "\n",
      "    accuracy                           0.77       638\n",
      "   macro avg       0.61      0.72      0.64       638\n",
      "weighted avg       0.85      0.77      0.79       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[387  75  35]\n",
      " [ 10  73   5]\n",
      " [  0  23  30]]\n",
      "AUC (macro average): 0.8095\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.78      0.87       663\n",
      "         1.0       0.47      0.61      0.53       118\n",
      "         2.0       0.37      0.90      0.53        70\n",
      "\n",
      "    accuracy                           0.77       851\n",
      "   macro avg       0.61      0.76      0.64       851\n",
      "weighted avg       0.86      0.77      0.79       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[517  73  73]\n",
      " [ 13  72  33]\n",
      " [  0   7  63]]\n",
      "AUC (macro average): 0.8293\n"
     ]
    }
   ],
   "source": [
    "lda_files = [\n",
    "    (\"../../data/dimension_reduction/lda/train_80.csv\", \"../../data/dimension_reduction/lda/test_20.csv\", \"8:2\"),\n",
    "    (\"../../data/dimension_reduction/lda/train_70.csv\", \"../../data/dimension_reduction/lda/test_30.csv\", \"7:3\"),\n",
    "    (\"../../data/dimension_reduction/lda/train_60.csv\", \"../../data/dimension_reduction/lda/test_40.csv\", \"6:4\")\n",
    "]\n",
    "\n",
    "for train_file, test_file, label in lda_files:\n",
    "    train_test_from_file(train_file, test_file, label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
