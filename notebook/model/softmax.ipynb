{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fb3913",
   "metadata": {},
   "source": [
    "# HỒI QUY SOFTMAX (MULTINOMIAL LOGISTIC REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e570b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183ec37",
   "metadata": {},
   "source": [
    "## Hàm softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966cffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(y, C):\n",
    "    Y = sparse.coo_matrix((np.ones_like(y), (y, np.arange(len(y)))), shape=(C, len(y))).toarray()\n",
    "    return Y\n",
    "\n",
    "def softmax_stable(Z):\n",
    "    e_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    return e_Z / e_Z.sum(axis=0)\n",
    "\n",
    "def softmax(Z):\n",
    "    e_Z = np.exp(Z)\n",
    "    return e_Z / e_Z.sum(axis=0)\n",
    "\n",
    "def softmax_regression(X, y, W_init, eta=0.05, tol=1e-4, max_count=10000):\n",
    "    W = [W_init]\n",
    "    C = W_init.shape[1]\n",
    "    Y = convert_labels(y, C)\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "\n",
    "    count = 0\n",
    "    check_w_after = 1500\n",
    "    while count < max_count:\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = Y[:, i].reshape(C, 1)\n",
    "            ai = softmax(np.dot(W[-1].T, xi))\n",
    "            W_new = W[-1] + eta * xi.dot((yi - ai).T)\n",
    "            count += 1\n",
    "            if count % check_w_after == 0:\n",
    "                if np.linalg.norm(W_new - W[-check_w_after]) < tol:\n",
    "                    return W\n",
    "            W.append(W_new)\n",
    "    return W\n",
    "\n",
    "#Thêm hiệu chỉnh L2 \n",
    "# def softmax_regression(X, y, W_init, eta=0.05, tol=1e-4, max_count=10000, lambda_reg=0.01):\n",
    "#     W = [W_init]\n",
    "#     C = W_init.shape[1]\n",
    "#     Y = convert_labels(y, C)\n",
    "#     N = X.shape[1]\n",
    "#     d = X.shape[0]\n",
    "\n",
    "#     count = 0\n",
    "#     check_w_after = 1500\n",
    "#     while count < max_count:\n",
    "#         mix_id = np.random.permutation(N)\n",
    "#         for i in mix_id:\n",
    "#             xi = X[:, i].reshape(d, 1)\n",
    "#             yi = Y[:, i].reshape(C, 1)\n",
    "#             ai = softmax(np.dot(W[-1].T, xi))\n",
    "\n",
    "#             # Cập nhật trọng số với regularization\n",
    "#             grad = xi.dot((yi - ai).T) - lambda_reg * W[-1]  # L2 regularization\n",
    "#             W_new = W[-1] + eta * grad\n",
    "\n",
    "#             count += 1\n",
    "#             if count % check_w_after == 0:\n",
    "#                 if np.linalg.norm(W_new - W[-check_w_after]) < tol:\n",
    "#                     return W\n",
    "#             W.append(W_new)\n",
    "#     return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c63ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dự đoán và đánh giá các chỉ số \n",
    "def pred(W, X):\n",
    "    A = softmax_stable(W.T.dot(X))\n",
    "    return np.argmax(A, axis=0)\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    auc = roc_auc_score(pd.get_dummies(y_true), pd.get_dummies(y_pred), average='macro', multi_class='ovr')\n",
    "    print(f\"AUC (macro average): {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654d3e3",
   "metadata": {},
   "source": [
    "## DỮ LIỆU GỐC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06f8be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dữ liệu\n",
    "df = pd.read_csv(\"../../data/data_processed/data_processed.csv\")\n",
    "\n",
    "# Tách đặc trưng và nhãn\n",
    "X = df.drop(columns=[\"NSP\"]).values\n",
    "y = df[\"NSP\"].values - 1  # Chuyển về 0,1,2\n",
    "\n",
    "# Chuẩn hóa\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Thêm bias\n",
    "X_scaled = np.hstack([np.ones((X_scaled.shape[0], 1)), X_scaled])\n",
    "C = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd137770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.94       332\n",
      "         1.0       0.65      0.61      0.63        59\n",
      "         2.0       0.85      0.66      0.74        35\n",
      "\n",
      "    accuracy                           0.88       426\n",
      "   macro avg       0.81      0.74      0.77       426\n",
      "weighted avg       0.88      0.88      0.88       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[317  12   3]\n",
      " [ 22  36   1]\n",
      " [  5   7  23]]\n",
      "AUC (macro average): 0.8121\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       497\n",
      "         1.0       0.59      0.61      0.60        88\n",
      "         2.0       0.87      0.64      0.74        53\n",
      "\n",
      "    accuracy                           0.88       638\n",
      "   macro avg       0.80      0.74      0.76       638\n",
      "weighted avg       0.88      0.88      0.88       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[474  20   3]\n",
      " [ 32  54   2]\n",
      " [  2  17  34]]\n",
      "AUC (macro average): 0.8153\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94       663\n",
      "         1.0       0.56      0.76      0.65       118\n",
      "         2.0       0.90      0.54      0.68        70\n",
      "\n",
      "    accuracy                           0.87       851\n",
      "   macro avg       0.81      0.74      0.76       851\n",
      "weighted avg       0.89      0.87      0.88       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[616  45   2]\n",
      " [ 26  90   2]\n",
      " [  7  25  38]]\n",
      "AUC (macro average): 0.8264\n"
     ]
    }
   ],
   "source": [
    "# Hàm huấn luyện và đánh giá với tỉ lệ cho trước\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_and_evaluate(X, y, test_size):\n",
    "    print(f\"\\n--- Tỉ lệ train:test = {int((1-test_size)*10)}:{int(test_size*10)} ---\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "\n",
    "    X_train_T = X_train.T\n",
    "    X_test_T = X_test.T\n",
    "    d = X_train_T.shape[0]\n",
    "\n",
    "    W_init = np.random.randn(d, C)\n",
    "    W = softmax_regression(X_train_T, y_train, W_init)[-1]\n",
    "\n",
    "    y_pred = pred(W, X_test_T)\n",
    "    evaluate_model(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Chạy với các tỉ lệ\n",
    "for test_size in [0.2, 0.3, 0.4]:\n",
    "    train_and_evaluate(X, y, test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b2309",
   "metadata": {},
   "source": [
    "Tỷ lệ train:test = 8:2\n",
    "Accuracy: 0.87\n",
    "F1-score (macro): 0.74\n",
    "AUC (macro): 0.8165\n",
    "\n",
    "Tỷ lệ train:test = 7:3\n",
    "Accuracy: 0.86\n",
    "F1-score (macro): 0.74\n",
    "AUC (macro): 0.8325\n",
    "\n",
    "Tỷ lệ train:test = 6:4\n",
    "Accuracy: 0.89 → cao nhất trong 3 tỷ lệ.\n",
    "F1-score (macro): 0.78 → cũng cao nhất.\n",
    "AUC (macro): 0.8344\n",
    "\n",
    "Nhận xét:\n",
    "Tỷ lệ train:test = 6:4 cho kết quả tốt nhất tổng thể (Accuracy, F1, AUC đều cao).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4588a",
   "metadata": {},
   "source": [
    "Lớp 1 (suspect) thường có precision và recall thấp do đặc điểm đặc trưng của nó nằm giữa hai lớp còn lại (normal và pathologic), khiến mô hình dễ nhầm lẫn. Đây là lớp trung gian về mặt y học, nên các đặc trưng không phân tách rõ ràng, dẫn đến việc mô hình thường dự đoán sai sang lớp 0 hoặc lớp 2. Đồng thời, softmax regression là mô hình tuyến tính nên càng gặp khó khăn khi ranh giới giữa các lớp không rõ ràng hoặc có sự chồng lấn trong không gian đặc trưng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c099a",
   "metadata": {},
   "source": [
    "## DỮ LIỆU GIẢM CHIỀU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489ce84",
   "metadata": {},
   "source": [
    "### GIẢM TRƯỚC CHIA SAU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c934533",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "309331cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Đánh giá với PCA ---\n",
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.95       332\n",
      "         1.0       0.68      0.58      0.62        59\n",
      "         2.0       0.81      0.74      0.78        35\n",
      "\n",
      "    accuracy                           0.89       426\n",
      "   macro avg       0.81      0.76      0.78       426\n",
      "weighted avg       0.89      0.89      0.89       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[320  10   2]\n",
      " [ 21  34   4]\n",
      " [  3   6  26]]\n",
      "AUC (macro average): 0.8281\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95       497\n",
      "         1.0       0.58      0.69      0.63        88\n",
      "         2.0       0.91      0.58      0.71        53\n",
      "\n",
      "    accuracy                           0.88       638\n",
      "   macro avg       0.81      0.74      0.76       638\n",
      "weighted avg       0.89      0.88      0.88       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[471  25   1]\n",
      " [ 25  61   2]\n",
      " [  3  19  31]]\n",
      "AUC (macro average): 0.8237\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.96       663\n",
      "         1.0       0.71      0.60      0.65       118\n",
      "         2.0       0.89      0.71      0.79        70\n",
      "\n",
      "    accuracy                           0.90       851\n",
      "   macro avg       0.85      0.76      0.80       851\n",
      "weighted avg       0.90      0.90      0.90       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[649  12   2]\n",
      " [ 43  71   4]\n",
      " [  3  17  50]]\n",
      "AUC (macro average): 0.8338\n"
     ]
    }
   ],
   "source": [
    "pca_df = pd.read_csv(\"../../data/dimension_reduction/pca/pca_all.csv\")\n",
    "pca_X = pca_df.drop(columns=[\"NSP\"]).values\n",
    "pca_y = pca_df[\"NSP\"].values - 1\n",
    "scaler = StandardScaler()\n",
    "pca_X_scaled = scaler.fit_transform(pca_X)\n",
    "\n",
    "print(\"--- Đánh giá với PCA ---\")\n",
    "for test_size in [0.2, 0.3, 0.4]:\n",
    "    train_and_evaluate(pca_X_scaled, pca_y, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8974105",
   "metadata": {},
   "source": [
    "### LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0d0da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Đánh giá với LDA ---\n",
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95       332\n",
      "         1.0       0.60      0.59      0.60        59\n",
      "         2.0       0.82      0.51      0.63        35\n",
      "\n",
      "    accuracy                           0.88       426\n",
      "   macro avg       0.78      0.69      0.73       426\n",
      "weighted avg       0.87      0.88      0.87       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[321   9   2]\n",
      " [ 22  35   2]\n",
      " [  3  14  18]]\n",
      "AUC (macro average): 0.7893\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95       497\n",
      "         1.0       0.65      0.60      0.63        88\n",
      "         2.0       0.85      0.66      0.74        53\n",
      "\n",
      "    accuracy                           0.89       638\n",
      "   macro avg       0.81      0.74      0.77       638\n",
      "weighted avg       0.89      0.89      0.89       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[480  15   2]\n",
      " [ 31  53   4]\n",
      " [  5  13  35]]\n",
      "AUC (macro average): 0.8187\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.97      0.94       663\n",
      "         1.0       0.66      0.53      0.59       118\n",
      "         2.0       0.85      0.66      0.74        70\n",
      "\n",
      "    accuracy                           0.88       851\n",
      "   macro avg       0.81      0.72      0.76       851\n",
      "weighted avg       0.88      0.88      0.88       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[644  17   2]\n",
      " [ 49  63   6]\n",
      " [  8  16  46]]\n",
      "AUC (macro average): 0.8007\n"
     ]
    }
   ],
   "source": [
    "lda_df = pd.read_csv(\"../../data/dimension_reduction/lda/lda_all.csv\")\n",
    "\n",
    "lda_X = lda_df.drop(columns=[\"NSP\"]).values\n",
    "lda_y = lda_df[\"NSP\"].values - 1\n",
    "lda_X_scaled = scaler.fit_transform(lda_X)\n",
    "\n",
    "print(\"\\n--- Đánh giá với LDA ---\")\n",
    "for test_size in [0.2, 0.3, 0.4]:\n",
    "  train_and_evaluate(lda_X_scaled, lda_y, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cd5ce",
   "metadata": {},
   "source": [
    "### So sánh và đánh giá kết quả\n",
    "1. Dữ liệu gốc\n",
    "- Accuracy: Tăng dần từ 0.87 → 0.89 khi tăng tỷ lệ dữ liệu huấn luyện.\n",
    "\n",
    "- Macro F1-score: Giao động quanh 0.74 → 0.78, tức là mô hình cân bằng khá tốt giữa các lớp.\n",
    "\n",
    "- AUC (macro): 0.8165 → 0.8344 — ổn định và tương đối cao.\n",
    "\n",
    "Ưu điểm:\n",
    "\n",
    "- Hiệu suất tổng thể khá tốt, đặc biệt với lớp 0.\n",
    "\n",
    "- Recall của lớp 1 (tập nhỏ) khá cao, đặc biệt khi test size lớn (0.81 ở tỷ lệ 7:3).\n",
    "\n",
    "Nhược điểm:\n",
    "\n",
    "- Precision và Recall cho lớp 2 chưa ổn định.\n",
    "\n",
    "- Có dấu hiệu mô hình học tốt lớp chiếm số đông, nhưng lớp ít (1, 2) vẫn chưa thực sự tốt.\n",
    "\n",
    "2. Dữ liệu PCA\n",
    "- Accuracy: Giảm còn ~0.74–0.77, tức là mô hình yếu hơn rõ rệt.\n",
    "\n",
    "- Macro F1-score: Chỉ còn 0.60–0.65, thấp hơn dữ liệu gốc.\n",
    "\n",
    "- AUC (macro): Tụt xuống khoảng 0.78–0.81.\n",
    "\n",
    "Nhận xét:\n",
    "\n",
    "- PCA là phương pháp giảm chiều không sử dụng nhãn lớp, nên thông tin phân biệt lớp bị mất.\n",
    "\n",
    "- Mô hình bị giảm hiệu năng rõ rệt, đặc biệt là với lớp 2 (precision và recall thấp).\n",
    "\n",
    "3. Dữ liệu LDA\n",
    "- Accuracy: Tăng nhẹ so với PCA (~0.76–0.77), nhưng vẫn thấp hơn dữ liệu gốc.\n",
    "\n",
    "- Macro F1-score: Giao động từ 0.62–0.65, khá sát với PCA.\n",
    "\n",
    "- AUC (macro): Đạt ~0.8088–0.8241, tốt hơn PCA, gần bằng dữ liệu gốc.\n",
    "\n",
    "Ưu điểm:\n",
    "\n",
    "- Recall lớp 1 và lớp 2 tăng rõ rệt, nhờ LDA tận dụng nhãn lớp khi giảm chiều.\n",
    "\n",
    "- Mô hình học tốt hơn so với PCA.\n",
    "\n",
    "Nhược điểm:\n",
    "\n",
    "- Precision cho lớp 2 vẫn thấp → mô hình vẫn chưa học tốt lớp ít dữ liệu.\n",
    "\n",
    "### Nhận xét chung mô hình softmax: \n",
    "Lớp 0 (chiếm đa số) luôn có precision và recall rất cao → mô hình dễ thiên lệch về lớp đa số.\n",
    "\n",
    "Khi tăng dữ liệu huấn luyện (giảm test size), mô hình thường có Recall lớp nhỏ tốt hơn, cho thấy mô hình cần nhiều dữ liệu để học tốt lớp thiểu số.\n",
    "\n",
    "Có dấu hiệu thiên lệch (bias) lớp, tức là không cân bằng trong phân loại."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b698960",
   "metadata": {},
   "source": [
    "## CHIA TRƯỚC GIẢM SAU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0598dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_from_file(train_path, test_path, test_ratio_label):\n",
    "    print(f\"\\n--- Tỉ lệ train:test = {test_ratio_label} ---\")\n",
    "    \n",
    "    # Đọc dữ liệu\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    X_train = train_df.drop(columns=['Unnamed: 0', \"NSP\"], axis=1).values.T\n",
    "    y_train = train_df['NSP'].values - 1\n",
    "    X_test = test_df.drop(columns=['Unnamed: 0', \"NSP\"], axis=1).values.T\n",
    "    y_test = test_df['NSP'].values - 1\n",
    "\n",
    "    # Huấn luyện\n",
    "    d = X_train.shape[0]\n",
    "    W_init = np.random.randn(d, C)\n",
    "    W = softmax_regression(X_train, y_train, W_init)[-1]\n",
    "\n",
    "    # Dự đoán và đánh giá\n",
    "    y_pred = pred(W, X_test)\n",
    "    evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef744904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.77      0.86       332\n",
      "         1.0       0.41      0.75      0.53        59\n",
      "         2.0       0.36      0.54      0.43        35\n",
      "\n",
      "    accuracy                           0.75       426\n",
      "   macro avg       0.58      0.69      0.61       426\n",
      "weighted avg       0.84      0.75      0.78       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257  47  28]\n",
      " [  9  44   6]\n",
      " [  0  16  19]]\n",
      "AUC (macro average): 0.7847\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.75      0.85       497\n",
      "         1.0       0.47      0.78      0.59        88\n",
      "         2.0       0.38      0.75      0.50        53\n",
      "\n",
      "    accuracy                           0.76       638\n",
      "   macro avg       0.61      0.76      0.65       638\n",
      "weighted avg       0.85      0.76      0.78       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[373  66  58]\n",
      " [ 11  69   8]\n",
      " [  1  12  40]]\n",
      "AUC (macro average): 0.8249\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88       663\n",
      "         1.0       0.53      0.56      0.55       118\n",
      "         2.0       0.41      0.79      0.54        70\n",
      "\n",
      "    accuracy                           0.79       851\n",
      "   macro avg       0.62      0.73      0.65       851\n",
      "weighted avg       0.83      0.79      0.80       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[551  44  68]\n",
      " [ 42  66  10]\n",
      " [  1  14  55]]\n",
      "AUC (macro average): 0.7947\n"
     ]
    }
   ],
   "source": [
    "pca_files = [\n",
    "    (\"../../data/dimension_reduction/pca/train_80.csv\", \"../../data/dimension_reduction/pca/test_20.csv\", \"8:2\"),\n",
    "    (\"../../data/dimension_reduction/pca/train_70.csv\", \"../../data/dimension_reduction/pca/test_30.csv\", \"7:3\"),\n",
    "    (\"../../data/dimension_reduction/pca/train_60.csv\", \"../../data/dimension_reduction/pca/test_40.csv\", \"6:4\"),\n",
    "]\n",
    "\n",
    "for train_file, test_file, label in pca_files:\n",
    "    train_test_from_file(train_file, test_file, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaa891cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tỉ lệ train:test = 8:2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.78      0.87       332\n",
      "         1.0       0.50      0.75      0.60        59\n",
      "         2.0       0.40      0.80      0.53        35\n",
      "\n",
      "    accuracy                           0.78       426\n",
      "   macro avg       0.62      0.78      0.67       426\n",
      "weighted avg       0.86      0.78      0.80       426\n",
      "\n",
      "Confusion Matrix:\n",
      "[[260  37  35]\n",
      " [  8  44   7]\n",
      " [  0   7  28]]\n",
      "AUC (macro average): 0.8361\n",
      "\n",
      "--- Tỉ lệ train:test = 7:3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.76      0.86       497\n",
      "         1.0       0.44      0.88      0.59        88\n",
      "         2.0       0.41      0.62      0.50        53\n",
      "\n",
      "    accuracy                           0.77       638\n",
      "   macro avg       0.61      0.75      0.65       638\n",
      "weighted avg       0.87      0.77      0.79       638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[380  77  40]\n",
      " [  4  77   7]\n",
      " [  0  20  33]]\n",
      "AUC (macro average): 0.8295\n",
      "\n",
      "--- Tỉ lệ train:test = 6:4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.78      0.87       663\n",
      "         1.0       0.44      0.90      0.59       118\n",
      "         2.0       0.49      0.60      0.54        70\n",
      "\n",
      "    accuracy                           0.78       851\n",
      "   macro avg       0.64      0.76      0.67       851\n",
      "weighted avg       0.87      0.78      0.81       851\n",
      "\n",
      "Confusion Matrix:\n",
      "[[518 106  39]\n",
      " [  7 106   5]\n",
      " [  0  28  42]]\n",
      "AUC (macro average): 0.8339\n"
     ]
    }
   ],
   "source": [
    "lda_files = [\n",
    "    (\"../../data/dimension_reduction/lda/train_80.csv\", \"../../data/dimension_reduction/lda/test_20.csv\", \"8:2\"),\n",
    "    (\"../../data/dimension_reduction/lda/train_70.csv\", \"../../data/dimension_reduction/lda/test_30.csv\", \"7:3\"),\n",
    "    (\"../../data/dimension_reduction/lda/train_60.csv\", \"../../data/dimension_reduction/lda/test_40.csv\", \"6:4\")\n",
    "]\n",
    "\n",
    "for train_file, test_file, label in lda_files:\n",
    "    train_test_from_file(train_file, test_file, label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
