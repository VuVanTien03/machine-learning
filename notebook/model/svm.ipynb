{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457d8cbf",
   "metadata": {},
   "source": [
    "# **Mô hình SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a81e61",
   "metadata": {},
   "source": [
    "## **Import thư viện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ec98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376de063",
   "metadata": {},
   "source": [
    "## **Đọc dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b891cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...   Min    Max  \\\n",
       "0  120.0  0.0  0.0  0.0  0.0  0.0  0.0  73.0   0.5  43.0  ...  62.0  126.0   \n",
       "1  132.0  4.0  0.0  4.0  2.0  0.0  0.0  17.0   2.1   0.0  ...  68.0  198.0   \n",
       "2  133.0  2.0  0.0  5.0  2.0  0.0  0.0  16.0   2.1   0.0  ...  68.0  198.0   \n",
       "3  134.0  2.0  0.0  6.0  2.0  0.0  0.0  16.0   2.4   0.0  ...  53.0  170.0   \n",
       "4  132.0  4.0  0.0  5.0  0.0  0.0  0.0  16.0   2.4   0.0  ...  53.0  170.0   \n",
       "\n",
       "   Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  NSP  \n",
       "0   2.0     0.0  120.0  137.0   121.0      73.0       1.0  2.0  \n",
       "1   6.0     1.0  141.0  136.0   140.0      12.0       0.0  1.0  \n",
       "2   5.0     1.0  141.0  135.0   138.0      13.0       0.0  1.0  \n",
       "3  11.0     0.0  137.0  134.0   137.0      13.0       1.0  1.0  \n",
       "4   9.0     0.0  137.0  136.0   138.0      11.0       1.0  1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/data_processed/data_processed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb9319",
   "metadata": {},
   "source": [
    "## **Xây dựng mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb456c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, X_test, y_train, y_test, kernel='rbf'):\n",
    "    # model = SVC(kernel=kernel, random_state=42)\n",
    "    model = SVC(kernel='rbf', class_weight='balanced', decision_function_shape='ovr')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"[Train] Classification Report:\")\n",
    "    print(classification_report(y_train, model.predict(X_train)))\n",
    "    \n",
    "    print(\"[Test] Classification Report:\")\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n",
    "\n",
    "# Xử lý dữ liệu gốc theo tỉ lệ và áp dụng SVM \n",
    "def process_original_data(df, ratio, kernel='rbf'):\n",
    "    X = df.drop('NSP', axis=1)\n",
    "    y = df['NSP']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=1 - ratio, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nMô hình SVM với dữ liệu gốc - Tỉ lệ = {int(ratio*10)}:{int((1-ratio)*10)} ---\")\n",
    "    evaluate_model(X_train, X_test, y_train, y_test, kernel=kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bbd0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_presplit_data(train_path, test_path, target_col='Target', kernel='rbf', method='PCA'):\n",
    "    # Đọc dữ liệu\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "\n",
    "    # Tách X và y\n",
    "    X_train = train_data.drop('Target', axis=1).values\n",
    "    y_train = train_data['Target'].values\n",
    "\n",
    "    X_test = test_data.drop('Target', axis=1).values\n",
    "    y_test = test_data['Target'].values\n",
    "\n",
    "    print(f\"\\nMô hình SVM với dữ liệu giảm chiều bằng {method} tỉ lệ {split}\")\n",
    "\n",
    "\n",
    "    # Huấn luyện và đánh giá\n",
    "    model = SVC(kernel=kernel, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"[Train] Classification Report:\")\n",
    "    print(classification_report(y_train, model.predict(X_train)))\n",
    "\n",
    "    print(\"[Test] Classification Report:\")\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba932c6",
   "metadata": {},
   "source": [
    "## **Dữ liệu gốc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f349ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mô hình SVM với dữ liệu gốc - Tỉ lệ = 8:1 ---\n",
      "[Train] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.90      0.94      1323\n",
      "         2.0       0.61      0.95      0.75       236\n",
      "         3.0       0.91      0.94      0.93       141\n",
      "\n",
      "    accuracy                           0.91      1700\n",
      "   macro avg       0.84      0.93      0.87      1700\n",
      "weighted avg       0.94      0.91      0.92      1700\n",
      "\n",
      "[Test] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.88      0.93       332\n",
      "         2.0       0.55      0.88      0.68        59\n",
      "         3.0       0.78      0.80      0.79        35\n",
      "\n",
      "    accuracy                           0.87       426\n",
      "   macro avg       0.77      0.85      0.80       426\n",
      "weighted avg       0.91      0.87      0.88       426\n",
      "\n",
      "\n",
      "Mô hình SVM với dữ liệu gốc - Tỉ lệ = 7:3 ---\n",
      "[Train] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.90      0.95      1158\n",
      "         2.0       0.62      0.96      0.75       207\n",
      "         3.0       0.93      0.93      0.93       123\n",
      "\n",
      "    accuracy                           0.91      1488\n",
      "   macro avg       0.85      0.93      0.88      1488\n",
      "weighted avg       0.94      0.91      0.92      1488\n",
      "\n",
      "[Test] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.88      0.93       497\n",
      "         2.0       0.54      0.90      0.68        88\n",
      "         3.0       0.84      0.79      0.82        53\n",
      "\n",
      "    accuracy                           0.88       638\n",
      "   macro avg       0.79      0.86      0.81       638\n",
      "weighted avg       0.92      0.88      0.89       638\n",
      "\n",
      "\n",
      "Mô hình SVM với dữ liệu gốc - Tỉ lệ = 6:4 ---\n",
      "[Train] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.90      0.95       992\n",
      "         2.0       0.62      0.97      0.76       177\n",
      "         3.0       0.93      0.93      0.93       106\n",
      "\n",
      "    accuracy                           0.91      1275\n",
      "   macro avg       0.85      0.93      0.88      1275\n",
      "weighted avg       0.94      0.91      0.92      1275\n",
      "\n",
      "[Test] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.98      0.89      0.93       663\n",
      "         2.0       0.56      0.88      0.68       118\n",
      "         3.0       0.87      0.83      0.85        70\n",
      "\n",
      "    accuracy                           0.88       851\n",
      "   macro avg       0.80      0.87      0.82       851\n",
      "weighted avg       0.92      0.88      0.89       851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in [0.8, 0.7, 0.6]:  \n",
    "    process_original_data(df, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d76b63",
   "metadata": {},
   "source": [
    "## **Dữ liệu giảm chiều bằng PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00c241b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mô hình SVM với dữ liệu giảm chiều bằng PCA tỉ lệ 80_20\n",
      "[Train] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.97      0.96      1323\n",
      "         2.0       0.76      0.75      0.75       236\n",
      "         3.0       1.00      0.82      0.90       141\n",
      "\n",
      "    accuracy                           0.93      1700\n",
      "   macro avg       0.90      0.85      0.87      1700\n",
      "weighted avg       0.93      0.93      0.93      1700\n",
      "\n",
      "[Test] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.97      0.95       332\n",
      "         2.0       0.67      0.63      0.65        59\n",
      "         3.0       0.88      0.66      0.75        35\n",
      "\n",
      "    accuracy                           0.90       426\n",
      "   macro avg       0.83      0.75      0.78       426\n",
      "weighted avg       0.89      0.90      0.89       426\n",
      "\n",
      "\n",
      "Mô hình SVM với dữ liệu giảm chiều bằng PCA tỉ lệ 70_30\n",
      "[Train] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.97      0.96      1158\n",
      "         2.0       0.76      0.76      0.76       207\n",
      "         3.0       1.00      0.82      0.90       123\n",
      "\n",
      "    accuracy                           0.93      1488\n",
      "   macro avg       0.91      0.85      0.88      1488\n",
      "weighted avg       0.93      0.93      0.93      1488\n",
      "\n",
      "[Test] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.97      0.95       497\n",
      "         2.0       0.66      0.65      0.65        88\n",
      "         3.0       0.92      0.66      0.77        53\n",
      "\n",
      "    accuracy                           0.90       638\n",
      "   macro avg       0.84      0.76      0.79       638\n",
      "weighted avg       0.90      0.90      0.89       638\n",
      "\n",
      "\n",
      "Mô hình SVM với dữ liệu giảm chiều bằng PCA tỉ lệ 60_40\n",
      "[Train] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.98      0.97       992\n",
      "         2.0       0.77      0.76      0.76       177\n",
      "         3.0       1.00      0.80      0.89       106\n",
      "\n",
      "    accuracy                           0.93      1275\n",
      "   macro avg       0.91      0.85      0.87      1275\n",
      "weighted avg       0.93      0.93      0.93      1275\n",
      "\n",
      "[Test] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.97      0.95       663\n",
      "         2.0       0.69      0.65      0.67       118\n",
      "         3.0       0.94      0.70      0.80        70\n",
      "\n",
      "    accuracy                           0.90       851\n",
      "   macro avg       0.85      0.77      0.81       851\n",
      "weighted avg       0.90      0.90      0.90       851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_paths_pca = {\n",
    "    \"80_20\": {\n",
    "        'train': r'..\\..\\data\\dimension_reduction\\pca\\train_80_20.csv',\n",
    "        'test': r'..\\..\\data\\dimension_reduction\\pca\\test_80_20.csv'\n",
    "    },\n",
    "    \"70_30\": {\n",
    "        'train': r'..\\..\\data\\dimension_reduction\\pca\\train_70_30.csv',\n",
    "        'test': r'..\\..\\data\\dimension_reduction\\pca\\test_70_30.csv'\n",
    "    },\n",
    "    \"60_40\": {\n",
    "        'train': r'..\\..\\data\\dimension_reduction\\pca\\train_60_40.csv',\n",
    "        'test': r'..\\..\\data\\dimension_reduction\\pca\\test_60_40.csv'\n",
    "    }\n",
    "}\n",
    "\n",
    "for split, paths in file_paths_pca.items():\n",
    "    process_presplit_data(\n",
    "        train_path=paths['train'],\n",
    "        test_path=paths['test'],\n",
    "        target_col='Target',\n",
    "        method=f'PCA'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c431d2a",
   "metadata": {},
   "source": [
    "## **Dữ liệu giảm chiều bằng LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2900051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mô hình SVM với dữ liệu giảm chiều bằng LDA tỉ lệ 80_20\n",
      "[Train] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.96      0.95      1323\n",
      "         2.0       0.69      0.67      0.68       236\n",
      "         3.0       0.93      0.76      0.84       141\n",
      "\n",
      "    accuracy                           0.90      1700\n",
      "   macro avg       0.85      0.80      0.82      1700\n",
      "weighted avg       0.90      0.90      0.90      1700\n",
      "\n",
      "[Test] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.96      0.95       332\n",
      "         2.0       0.67      0.71      0.69        59\n",
      "         3.0       0.85      0.66      0.74        35\n",
      "\n",
      "    accuracy                           0.90       426\n",
      "   macro avg       0.82      0.78      0.79       426\n",
      "weighted avg       0.90      0.90      0.90       426\n",
      "\n",
      "\n",
      "Mô hình SVM với dữ liệu giảm chiều bằng LDA tỉ lệ 70_30\n",
      "[Train] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.95      0.95      1158\n",
      "         2.0       0.69      0.71      0.70       207\n",
      "         3.0       0.92      0.79      0.85       123\n",
      "\n",
      "    accuracy                           0.91      1488\n",
      "   macro avg       0.85      0.82      0.83      1488\n",
      "weighted avg       0.91      0.91      0.90      1488\n",
      "\n",
      "[Test] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.95      0.95       497\n",
      "         2.0       0.63      0.73      0.68        88\n",
      "         3.0       0.89      0.64      0.75        53\n",
      "\n",
      "    accuracy                           0.89       638\n",
      "   macro avg       0.82      0.77      0.79       638\n",
      "weighted avg       0.90      0.89      0.89       638\n",
      "\n",
      "\n",
      "Mô hình SVM với dữ liệu giảm chiều bằng LDA tỉ lệ 60_40\n",
      "[Train] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.96      0.95       992\n",
      "         2.0       0.69      0.68      0.69       177\n",
      "         3.0       0.95      0.75      0.84       106\n",
      "\n",
      "    accuracy                           0.90      1275\n",
      "   macro avg       0.86      0.80      0.83      1275\n",
      "weighted avg       0.90      0.90      0.90      1275\n",
      "\n",
      "[Test] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.96      0.95       663\n",
      "         2.0       0.67      0.72      0.70       118\n",
      "         3.0       0.89      0.67      0.76        70\n",
      "\n",
      "    accuracy                           0.90       851\n",
      "   macro avg       0.84      0.78      0.80       851\n",
      "weighted avg       0.90      0.90      0.90       851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_paths_lda = {\n",
    "    \"80_20\": {\n",
    "        'train': r'..\\..\\data\\dimension_reduction\\lda\\train_80_20.csv',\n",
    "        'test': r'..\\..\\data\\dimension_reduction\\lda\\test_80_20.csv'\n",
    "    },\n",
    "    \"70_30\": {\n",
    "        'train': r'..\\..\\data\\dimension_reduction\\lda\\train_70_30.csv',\n",
    "        'test': r'..\\..\\data\\dimension_reduction\\lda\\test_70_30.csv'\n",
    "    },\n",
    "    \"60_40\": {\n",
    "        'train': r'..\\..\\data\\dimension_reduction\\lda\\train_60_40.csv',\n",
    "        'test': r'..\\..\\data\\dimension_reduction\\lda\\test_60_40.csv'\n",
    "    }\n",
    "}\n",
    "\n",
    "for split, paths in file_paths_lda.items():\n",
    "    process_presplit_data(\n",
    "        train_path=paths['train'],\n",
    "        test_path=paths['test'],\n",
    "        target_col='Target',\n",
    "        method=f'LDA'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8897a9",
   "metadata": {},
   "source": [
    "### 1. **PCA có thể giúp SVM hoạt động hiệu quả hơn trong không gian ít nhiễu**\n",
    "- **PCA** tìm chiều không gian mới sao cho **giữ lại phương sai lớn nhất**, giúp loại bỏ nhiễu và các chiều không đóng góp nhiều thông tin. Điều này đặc biệt hữu ích cho các mô hình **nhạy với nhiễu** như SVM.\n",
    "- Khi dữ liệu gốc chứa nhiều chiều dư thừa (high-dimensional noise), SVM trên dữ liệu gốc sẽ **khó tìm biên phân cách tối ưu** => giảm chính xác.\n",
    "\n",
    "###  2. **LDA có thể overfit nếu số chiều sau giảm thấp hoặc phân bố không đều**\n",
    "- LDA tối ưu hóa việc **phân tách các lớp** thông qua ma trận giữa và trong lớp, nhưng nếu dữ liệu không phân tách tuyến tính rõ ràng, hoặc số mẫu của mỗi lớp chênh lệch lớn → **LDA không mạnh bằng PCA**.\n",
    "- LDA giới hạn số chiều sau giảm = `số lớp - 1` (ví dụ có 3 lớp thì tối đa còn 2 chiều) → mất thông tin → hạn chế khả năng biểu diễn cho SVM (nhất là kernel SVM).\n",
    "\n",
    "### 3. **Kernel SVM + PCA = kết hợp tốt**\n",
    "- SVM dùng kernel `rbf` (phi tuyến) có thể **học được ranh giới phi tuyến phức tạp**. PCA giữ được thông tin quan trọng → giúp kernel hoạt động hiệu quả hơn.\n",
    "- Trong khi đó, nếu đầu vào chỉ còn 2 chiều (như LDA với 3 lớp), **biên phân cách trong không gian giảm** có thể không đủ linh hoạt cho SVM.\n",
    "\n",
    "\n",
    "### Tóm lại:\n",
    "\n",
    "| Mô hình | Ưu điểm | Nhược điểm |\n",
    "|--------|---------|-------------|\n",
    "| **Gốc (raw)** | Đầy đủ thông tin | Dễ nhiễu, overfit |\n",
    "| **PCA** | Giảm nhiễu, giữ phương sai | Không phân biệt lớp |\n",
    "| **LDA** | Phân biệt lớp tốt | Mất thông tin nếu lớp lệch, chỉ còn `n_classes - 1` chiều |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
